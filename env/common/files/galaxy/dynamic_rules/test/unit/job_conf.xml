<?xml version="1.0"?>
<job_conf>
    <plugins workers="8">
        <plugin id="dynamic" type="runner">
            <!-- These live in the virtualenv -->
            <param id="rules_module">usegalaxy.jobs.rules</param>
        </plugin>
        <plugin id="local" type="runner" load="galaxy.jobs.runners.local:LocalJobRunner"/>
        <plugin id="slurm" type="runner" load="galaxy.jobs.runners.slurm:SlurmJobRunner">
            <param id="drmaa_library_path">/usr/lib64/libdrmaa.so</param>
            <param id="invalidjobexception_retries">5</param>
            <param id="internalexception_retries">5</param>
        </plugin>
        <expand macro="pulsar_plugin" id="jetstream_iu" />
        <expand macro="pulsar_plugin" id="jetstream_iu_nagios" />
        <expand macro="pulsar_plugin" id="jetstream_tacc" />
        <expand macro="pulsar_plugin" id="jetstream_tacc_nagios" />
        <expand macro="pulsar_plugin" id="stampede" />
        <expand macro="pulsar_plugin" id="stampede_nagios" />
        <expand macro="pulsar_plugin" id="bridges" />
        <expand macro="pulsar_plugin" id="bridges_nagios" />
    </plugins>
    <handlers default="handlers">
        <expand macro="normal_handler" hostid="3" id="0" />
        <expand macro="normal_handler" hostid="3" id="1" />
        <expand macro="multi_handler" hostid="3" id="2" />
        <expand macro="normal_handler" hostid="4" id="0" />
        <expand macro="normal_handler" hostid="4" id="1" />
        <expand macro="multi_handler" hostid="4" id="2" />
    </handlers>
    <destinations default="dynamic_normal_reserved">
        <!-- dynamic function for setting roundup multi walltime, also handles the explicit stampede resource selector -->
        <expand macro="dynamic_destination" dest="local_stampede_select_dynamic_walltime" />
        <!-- dynamic function for the multi-or-bridges selector -->
        <expand macro="dynamic_destination" dest="multi_bridges_select" />
        <!-- dynamic method for the stampede-only selector -->
        <expand macro="dynamic_destination" dest="stampede_select" />
        <!-- dynamic method for the bridges-only selector -->
        <expand macro="dynamic_destination" dest="bridges_select" />
        <!-- dynamic memory rule for the naive variant caller -->
        <expand macro="dynamic_destination" dest="nvc_dynamic_memory" />

        <!-- dynamic local/reserved destinations-->
        <expand macro="slurm_reserved_destination" dest="normal" partition="normal" native_specification="--cpus-per-task=1 --time=36:00:00" />
        <expand macro="slurm_reserved_destination" dest="normal_16gb" partition="normal" native_specification="--cpus-per-task=1 --time=36:00:00 --mem-per-cpu=15360" java_mem="15g" />
        <expand macro="slurm_reserved_destination" dest="normal_32gb" partition="normal" native_specification="--cpus-per-task=1 --time=36:00:00 --mem-per-cpu=30720" java_mem="30g" />
        <expand macro="slurm_reserved_destination" dest="normal_64gb" partition="normal" native_specification="--cpus-per-task=1 --time=36:00:00 --mem-per-cpu=61440" java_mem="60g" />
        <expand macro="slurm_reserved_destination" dest="multi" partition="multi" native_specification="--cpus-per-task=6 --time=36:00:00 --mem=8192" java_mem="30g" />

        <!-- local destinations -->
        <expand macro="slurm_destination" dest="multi_development" partition="normal" native_specification="--cpus-per-task=2 --time=00:30:00 --mem-per-cpu=5120" java_mem="10g" />

        <!-- temporary concurrency limit increase for du novo: align families -->
        <expand macro="slurm_destination" dest="multi_align_families" partition="multi" native_specification="--cpus-per-task=6 --time=96:00:00" />

        <!-- dynamic modified destinations: do not use directly -->
        <expand macro="slurm_destination" dest="multi_dynamic_walltime" partition="multi" native_specification="--cpus-per-task=6" />
        <!-- <resubmit condition="walltime_reached" destination="stampede_normal" handler="multi_handlers"/> -->
        <expand macro="slurm_destination" dest="normal_dynamic_mem" partition="normal" native_specification="--cpus-per-task=1 --time=24:00:00" />

        <!-- jetstream destinations -->
        <destination id="jetstream_multi" runner="dynamic">
            <!-- this destination exists for the dynamic runner to read the native spec for testing -->
            <param id="nativeSpecification">--time=36:00:00 --nodes=1 --partition=multi</param>
        </destination>
        <expand macro="jetstream_destination" id="small" site="iu" native_specification="--partition=small --time=36:00:00 --mem=3584" />
        <expand macro="jetstream_destination" id="normal" site="iu" native_specification="--partition=normal --time=36:00:00 --mem=7168" />
        <expand macro="jetstream_destination" id="multi" site="iu" native_specification="--partition=multi --time=36:00:00 --mem=28672" />
        <expand macro="jetstream_nagios_destination" site="iu" />
        <expand macro="jetstream_destination" id="multi" site="tacc" native_specification="--partition=multi --nodes=1 --time=36:00:00" />
        <expand macro="jetstream_nagios_destination" site="tacc" />

        <!-- test -->
        <expand macro="jetstream_destination" id="reserved" site="iu" native_specification="--partition=reserved --nodes=1 --time=36:00:00" />

        <!-- stampede destinations -->
        <expand macro="stampede_destination" id="normal" native_specification="--partition=normal --nodes=1 --cpus-per-task=16 --time=48:00:00 --account=TG-MCB140147" />
        <expand macro="stampede_destination" id="development" native_specification="--partition=development --nodes=1 --cpus-per-task=16 --time=00:30:00 --account=TG-MCB140147" />
        <expand macro="stampede_nagios_destination" />

        <!-- bridges destinations -->
        <!-- walltime and mem are set dynamically -->
        <!-- use constraint to avoid running on xl nodes, which do not mount /pylon5 -->
        <expand macro="bridges_destination" id="normal" native_specification="-p LM --constraint=LM --mem=8192" />
        <!-- 147456 MB == 144 GB (3 cores) (128GB is the minimum for LM) -->
        <expand macro="bridges_destination" id="development" native_specification="-p LM --constraint=LM -t 00:30:00 --mem=147456" />
        <expand macro="bridges_nagios_destination" />

        <!-- local destination for nagios handler checks -->
        <destination id="local" runner="local"/>

    </destinations>
    <tools>
        <!-- multi/stampede jobs -->
        <expand macro="stampede_resubmit_tool" id="bowtie2" />
        <expand macro="stampede_resubmit_tool" id="bowtie_wrapper" />
        <expand macro="stampede_resubmit_tool" id="bwa" />
        <expand macro="stampede_resubmit_tool" id="bwa_mem" />
        <expand macro="stampede_resubmit_tool" id="bwa_wrapper" />
        <expand macro="stampede_resubmit_tool" id="cuffdiff" />
        <expand macro="stampede_resubmit_tool" id="cufflinks" />
        <expand macro="stampede_resubmit_tool" id="cuffmerge" />
        <expand macro="stampede_resubmit_tool" id="cuffnorm" />
        <expand macro="stampede_resubmit_tool" id="cuffquant" />
        <expand macro="stampede_resubmit_tool" id="tophat" />
        <expand macro="stampede_resubmit_tool" id="tophat2" />
        <expand macro="stampede_resubmit_tool" id="stringtie" />
        <expand macro="stampede_resubmit_tool" id="hisat2" />
        <expand macro="stampede_resubmit_tool" id="prokka" />
        <expand macro="stampede_resubmit_tool" id="rbc_mafft" />
        <expand macro="stampede_resubmit_tool" id="deeptools_bam_compare" />
        <expand macro="stampede_resubmit_tool" id="deeptools_bam_coverage" />
        <expand macro="stampede_resubmit_tool" id="deeptools_bam_pe_fragmentsize" />
        <expand macro="stampede_resubmit_tool" id="deeptools_bigwig_compare" />
        <expand macro="stampede_resubmit_tool" id="deeptools_compute_gc_bias" />
        <expand macro="stampede_resubmit_tool" id="deeptools_compute_matrix" />
        <expand macro="stampede_resubmit_tool" id="deeptools_correct_gc_bias" />
        <expand macro="stampede_resubmit_tool" id="deeptools_multi_bam_summary" />
        <expand macro="stampede_resubmit_tool" id="deeptools_multi_bigwig_summary" />
        <expand macro="stampede_resubmit_tool" id="deeptools_plot_coverage" />
        <expand macro="stampede_resubmit_tool" id="deeptools_plot_fingerprint" />
        <expand macro="stampede_resubmit_tool" id="kraken" />
        <expand macro="stampede_resubmit_tool" id="dexseq" />
        <expand macro="stampede_resubmit_tool" id="hifive" />
        <!-- explicit stampede jobs -->
        <expand macro="stampede_tool" id="megablast_wrapper" />
        <!-- new LASTZ wrapper is not multicore, but it may need more memory
             <expand macro="stampede_tool" id="lastz_wrapper_2" /> -->
        <expand macro="stampede_tool" id="bwa_color_wrapper" />
        <expand macro="stampede_tool" id="bowtie_color_wrapper" />
        <!-- bridges jobs -->
        <expand macro="bridges_tool" id="trinity_psc" />
        <expand macro="bridges_tool" id="spades" />
        <expand macro="bridges_tool" id="unicycler" />
        <expand macro="bridges_tool" id="star_fusion" />
        <!-- trackster jobs -->
        <tool id="cufflinks" destination="slurm_trackster_multi">
            <param id="source">trackster</param>
        </tool>
        <!-- dynamic memory tools -->
        <tool id="naive_variant_caller" destination="dynamic_nvc_dynamic_memory"/>
        <!-- local/jetstream tools -->
        <!--
        <tool id="align_families" destination="dynamic_local_stampede_select_dynamic_walltime" handler="multi_handlers" resources="local_or_stampede"/>
        -->
        <tool id="align_families" destination="slurm_multi_align_families" handler="multi_handlers"/>
        <!-- roundup multi/jetstream/bridges jobs -->
        <tool id="rna_star" destination="dynamic_multi_bridges_select" handler="multi_handlers"  resources="multi_or_bridges"/>
        <!-- 16GB tools -->
        <tool id="join1" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gops_join_1" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_unified_genotyper" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_realigner_target_creator" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_indel_realigner" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_depth_of_coverage" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_variant_recalibrator" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_count_covariates" destination="dynamic_normal_16gb_reserved"/>
        <tool id="gatk_table_recalibration" destination="dynamic_normal_16gb_reserved"/>
        <tool id="fastq_paired_end_joiner" destination="dynamic_normal_16gb_reserved"/>
        <tool id="bamtools" destination="dynamic_normal_16gb_reserved"/>
        <tool id="varscan" destination="dynamic_normal_16gb_reserved"/>
        <tool id="scatterplot_rpy" destination="dynamic_normal_16gb_reserved"/>
        <tool id="htseq_count" destination="dynamic_normal_16gb_reserved"/>
        <tool id="flanking_features_1" destination="dynamic_normal_16gb_reserved"/>
        <tool id="cummeRbund" destination="dynamic_normal_16gb_reserved"/>
        <tool id="collection_column_join" destination="dynamic_normal_16gb_reserved"/>
        <tool id="correct_barcodes" destination="dynamic_normal_16gb_reserved"/>
        <tool id="rseqc_read_duplication" destination="dynamic_normal_16gb_reserved"/>
        <tool id="rseqc_RPKM_saturation" destination="dynamic_normal_16gb_reserved"/>
        <tool id="rseqc_bam2wig" destination="dynamic_normal_16gb_reserved"/>
        <!-- 32GB tools -->
        <tool id="Interval2Maf1" destination="dynamic_normal_32gb_reserved"/>
        <!-- 64GB tools -->
        <tool id="wig_to_bigWig" destination="dynamic_normal_64gb_reserved"/>
        <tool id="CONVERTER_bedgraph_to_bigwig" destination="dynamic_normal_64gb_reserved"/>
        <!-- jetstream autoscale test -->
        <tool id="toolshed.g2.bx.psu.edu/repos/devteam/fastx_collapser/cshl_fastx_collapser/1.0.1" destination="jetstream_iu_small" handler="multi_handlers" />
        <tool id="toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_sed_tool/1.1.0" destination="jetstream_iu_small" handler="multi_handlers" />
        <tool id="toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_awk_tool/1.1.0" destination="jetstream_iu_small" handler="multi_handlers" />
        <!-- nagios checks -->
        <!-- run wherever it lands
        <tool id="echo_main_cluster"/>
        -->
        <tool id="echo_main_w3_handler0" destination="local" handler="main_w3_handler0"/>
        <tool id="echo_main_w3_handler1" destination="local" handler="main_w3_handler1"/>
        <tool id="echo_main_w3_handler2" destination="local" handler="main_w3_handler2"/>
        <tool id="echo_main_w4_handler0" destination="local" handler="main_w4_handler0"/>
        <tool id="echo_main_w4_handler1" destination="local" handler="main_w4_handler1"/>
        <tool id="echo_main_w4_handler2" destination="local" handler="main_w4_handler2"/>
        <tool id="echo_main_jetstream_iu" destination="jetstream_iu_nagios" handler="multi_handlers"/>
        <tool id="echo_main_jetstream_tacc" destination="jetstream_tacc_nagios" handler="multi_handlers"/>
        <tool id="echo_main_stampede" destination="stampede_nagios" handler="multi_handlers"/>
        <tool id="echo_main_bridges" destination="bridges_nagios" handler="multi_handlers"/>
    </tools>
    <resources default="default">
        <group id="default"></group>
        <group id="local_or_stampede">tacc_compute_resource</group>
        <group id="multi_or_bridges">multi_bridges_compute_resource</group>
        <group id="stampede">stampede_compute_resource</group>
        <group id="bridges">bridges_compute_resource</group>
    </resources>
    <limits>
        <!--
        <limit type="registered_user_concurrent_jobs">6</limit>
        -->
        <limit type="anonymous_user_concurrent_jobs">1</limit>
        <limit type="job_walltime">49:00:00</limit>
        <limit type="output_size">200G</limit>
        <!-- per-destination per-user limits -->
        <limit type="destination_user_concurrent_jobs" id="slurm_normal">4</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_normal_16gb">1</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_normal_64gb">1</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_multi">2</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_multi_dynamic_walltime">2</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_multi_development">1</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_multi_trackster">1</limit>
        <limit type="destination_user_concurrent_jobs" id="slurm_multi_align_families">4</limit>
        <limit type="destination_user_concurrent_jobs" id="reserved_normal">16</limit>
        <limit type="destination_user_concurrent_jobs" id="reserved_normal_16gb">8</limit>
        <limit type="destination_user_concurrent_jobs" id="reserved_normal_32gb">4</limit>
        <limit type="destination_user_concurrent_jobs" id="reserved_normal_64gb">2</limit>
        <limit type="destination_user_concurrent_jobs" id="reserved_multi">8</limit>
        <limit type="destination_user_concurrent_jobs" id="stampede_normal">4</limit>
        <limit type="destination_user_concurrent_jobs" id="stampede_development">1</limit>
        <!--
        <limit type="destination_user_concurrent_jobs" id="bridges_normal">1</limit>
        <limit type="destination_user_concurrent_jobs" id="bridges_development">1</limit>
        -->
        <limit type="destination_user_concurrent_jobs" id="jetstream">4</limit>
        <!-- per-destination total limits -->
        <limit type="destination_total_concurrent_jobs" id="stampede_normal">50</limit>
        <limit type="destination_total_concurrent_jobs" id="stampede_development">1</limit>
        <!--
        <limit type="destination_total_concurrent_jobs" id="bridges_normal">10</limit>
        <limit type="destination_total_concurrent_jobs" id="bridges_development">1</limit>
        -->
    </limits>
    <macros>
        <xml name="pulsar_plugin" tokens="id">
            <plugin id="pulsar_@ID@" type="runner" load="galaxy.jobs.runners.pulsar:PulsarMQJobRunner">
                <param id="amqp_url">galaxy_job_conf_amqp_url </param>
                <param id="galaxy_url">https://inventory_hostname_short .galaxyproject.org</param>
                <param id="manager">@ID@</param>
                <param id="persistence_directory">/srv/galaxy/galaxy_instance_codename /var/pulsar_amqp_ack</param>
                <param id="amqp_acknowledge">True</param>
                <param id="amqp_ack_republish_time">300</param>
                <param id="amqp_consumer_timeout">2.0</param>
                <param id="amqp_publish_retry">True</param>
                <param id="amqp_publish_retry_max_retries">60</param>
            </plugin>
        </xml>
        <xml name="normal_handler" tokens="id,hostid">
            <handler id="main_w@HOSTID@_handler@ID@" tags="handlers">
                <plugin id="local"/>
                <plugin id="slurm"/>
            </handler>
        </xml>
        <xml name="multi_handler" tokens="id,hostid">
            <handler id="main_w@HOSTID@_handler@ID@" tags="multi_handlers">
                <plugin id="local"/>
                <plugin id="slurm"/>
                <plugin id="pulsar_jetstream_iu"/>
                <plugin id="pulsar_jetstream_iu_nagios"/>
                <plugin id="pulsar_jetstream_tacc"/>
                <plugin id="pulsar_jetstream_tacc_nagios"/>
                <plugin id="pulsar_stampede"/>
                <plugin id="pulsar_stampede_nagios"/>
                <plugin id="pulsar_bridges"/>
                <plugin id="pulsar_bridges_nagios"/>
            </handler>
        </xml>
        <xml name="dynamic_destination" tokens="dest">
            <destination id="dynamic_@DEST@" runner="dynamic">
                <param id="type">python</param>
                <param id="function">dynamic_@DEST@</param>
            </destination>
        </xml>
        <xml name="slurm_destination" tokens="dest,partition,native_specification,java_mem" token_java_mem="7g">
            <destination id="slurm_@DEST@" runner="slurm">
                <param id="nativeSpecification">--partition=@PARTITION@ --nodes=1 @NATIVE_SPECIFICATION@</param>
                <expand macro="dest_local_env" java_mem="@JAVA_MEM@ "/>
            </destination>
        </xml>
        <xml name="slurm_reserved_destination" tokens="dest,partition,native_specification,java_mem" token_java_mem="7g">
            <expand macro="dynamic_destination" dest="@DEST@_reserved" />
            <expand macro="slurm_destination" dest="@DEST@" partition="@PARTITION@" native_specification="@NATIVE_SPECIFICATION@" java_mem="@JAVA_MEM@" />
            <destination id="reserved_@DEST@" runner="slurm">
                <param id="nativeSpecification">--clusters=roundup --partition=reserved --nodes=1 @NATIVE_SPECIFICATION@</param>
                <expand macro="dest_local_env" java_mem="@JAVA_MEM@" />
            </destination>
        </xml>
        <!-- some unfortunate duplication here because macro expansions in the macro attribute of an expand tag is not supported -->
        <xml name="jetstream_destination" tokens="id,site,native_specification">
            <!-- the "jetstream" tag is for limits -->
            <destination id="jetstream_@SITE@_@ID@" runner="pulsar_jetstream_@SITE@" tags="jetstream">
                <param id="remote_metadata">true</param>
                <param id="submit_native_specification">@NATIVE_SPECIFICATION@</param>
                <expand macro="dest_pulsar_common_params" />
                <expand macro="dest_pulsar_jetstream_params" />
            </destination>
        </xml>
        <xml name="jetstream_nagios_destination" tokens="site">
            <destination id="jetstream_@SITE@_nagios" runner="pulsar_jetstream_@SITE@_nagios">
                <expand macro="dest_pulsar_common_params" />
                <expand macro="dest_pulsar_jetstream_params" />
            </destination>
        </xml>
        <xml name="stampede_destination" tokens="id,native_specification">
            <destination id="stampede_@ID@" runner="pulsar_stampede">
                <param id="remote_metadata">true</param>
                <param id="submit_native_specification">@NATIVE_SPECIFICATION@</param>
                <expand macro="dest_pulsar_common_params" />
                <expand macro="dest_pulsar_stampede_params" />
            </destination>
        </xml>
        <xml name="stampede_nagios_destination">
            <destination id="stampede_nagios" runner="pulsar_stampede_nagios">
                <expand macro="dest_pulsar_common_params" />
                <expand macro="dest_pulsar_stampede_params" />
            </destination>
        </xml>
        <xml name="bridges_destination" tokens="id,native_specification">
            <destination id="bridges_@ID@" runner="pulsar_bridges">
                <param id="remote_metadata">true</param>
                <param id="submit_native_specification">@NATIVE_SPECIFICATION@</param>
                <expand macro="dest_pulsar_common_params" />
                <expand macro="dest_pulsar_bridges_params" />
            </destination>
        </xml>
        <xml name="bridges_nagios_destination">
            <destination id="bridges_nagios" runner="pulsar_bridges_nagios">
                <expand macro="dest_pulsar_common_params" />
                <expand macro="dest_pulsar_bridges_params" />
            </destination>
        </xml>
        <xml name="dest_local_env" tokens="java_mem" token_java_mem="7g">
            <!-- cloudmap tools are still using R 2.11(!) from here, also the genome diversity tools use things in /galaxy/software -->
            <env id="PATH">/cvmfs/galaxy_instance_codename .galaxyproject.org/deps/_manual/bin:/galaxy/galaxy_instance_codename /linux-x86_64/bin:/galaxy/software/linux-x86_64/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin</env>
            <env id="LD_LIBRARY_PATH">/cvmfs/galaxy_instance_codename .galaxyproject.org/venv/lib</env>
            <expand macro="dest_tmp_env" />
            <env id="_JAVA_OPTIONS">$_JAVA_OPTIONS -Xmx@JAVA_MEM@ -Xms256m</env>
            <!-- explicit venv activation is necessary until we upgrade to 17.09 (slurm is passing $VIRTUAL_ENV but we reset $PATH) -->
            <env file="/cvmfs/galaxy_instance_codename .galaxyproject.org/venv/bin/activate" />
        </xml>
        <xml name="dest_tmp_env">
            <env id="XDG_DATA_HOME">/cvmfs/galaxy_instance_codename .galaxyproject.org/xdg/data</env>
            <env id="TEMP">$(dirname ${BASH_SOURCE[0]})/_job_tmp</env>
            <env id="TMPDIR">$TEMP</env>
            <env id="_JAVA_OPTIONS">-Djava.io.tmpdir=$TEMP</env>
            <env exec="mkdir -p $TEMP" />
        </xml>
        <xml name="dest_pulsar_common_params">
            <param id="transport">curl</param>
            <param id="default_file_action">remote_transfer</param>
            <param id="dependency_resolution">remote</param>
            <param id="rewrite_parameters">true</param>
            <param id="submit_user_email">$__user_email__</param>
            <env id="LC_ALL">C</env>
        </xml>
        <xml name="dest_pulsar_jetstream_params">
            <param id="use_remote_datatypes">true</param>
            <param id="remote_property_galaxy_datatypes_config_file">/cvmfs/galaxy_instance_codename .galaxyproject.org/galaxy/config/datatypes_conf.xml.sample</param>
            <param id="jobs_directory">/jetstream/scratch0/galaxy_instance_codename /jobs</param>
            <param id="remote_property_galaxy_home">/cvmfs/galaxy_instance_codename .galaxyproject.org/galaxy</param>
            <!-- this doesn't work, set in supervisor environment instead
            <param id="remote_property_galaxy_virtual_env">/cvmfs/galaxy_instance_codename .galaxyproject.org/venv</param>
            -->
            <param id="file_action_config">galaxy_config_dir /pulsar_jetstream_actions.yml</param>
            <env id="PATH">/jetstream/scratch0/main/conda/envs/set_metadata@20171114/bin:$PATH</env>
            <expand macro="dest_tmp_env" />
        </xml>
        <xml name="dest_pulsar_stampede_params">
            <param id="use_remote_datatypes">true</param>
            <param id="remote_property_galaxy_datatypes_config_file">/work/galaxy/galaxy_instance_codename /galaxy/server/config/datatypes_conf.xml.sample</param>
            <param id="jobs_directory">/scratch/03166/xcgalaxy/galaxy_instance_codename /staging/</param>
            <param id="remote_property_galaxy_home">/work/galaxy/galaxy_instance_codename /galaxy/server</param>
            <!-- this doesn't work, set in supervisor environment instead
            <param id="remote_property_galaxy_virtual_env">/work/galaxy/galaxy_instance_codename /galaxy/venv</param>
            -->
            <param id="file_action_config">galaxy_config_dir /pulsar_stampede_actions.yml</param>
            <env exec="eval `/opt/apps/lmod/lmod/libexec/lmod bash purge`" />
        </xml>
        <xml name="dest_pulsar_bridges_params">
            <param id="use_remote_datatypes">true</param>
            <param id="remote_property_galaxy_datatypes_config_file">/pylon5/mc48nsp/xcgalaxy/galaxy_instance_codename /galaxy/server/config/datatypes_conf.xml.sample</param>
            <param id="jobs_directory">/pylon5/mc48nsp/xcgalaxy/galaxy_instance_codename /staging/</param>
            <param id="remote_property_galaxy_home">/pylon5/mc48nsp/xcgalaxy/galaxy_instance_codename /galaxy/server</param>
            <!-- this doesn't work, set in supervisor environment instead
            <param id="remote_property_galaxy_virtual_env">/pylon5/mc48nsp/xcgalaxy/galaxy_instance_codename /galaxy/venv</param>
            -->
            <param id="file_action_config">galaxy_config_dir /pulsar_bridges_actions.yml</param>
            <env exec="eval `modulecmd sh purge`" />
            <!-- https://bugs.openjdk.java.net/browse/JDK-7085890 -->
            <env id="PATH">/pylon5/mc48nsp/xcgalaxy/openjdk8/bin:$PATH</env>
            <env id="_JAVA_OPTIONS">-Dsun.zip.disableMemoryMapping=true</env>
        </xml>
        <xml name="multi_tool" tokens="id">
            <tool id="@ID@" destination="dynamic_multi_reserved" handler="multi_handlers" />
        </xml>
        <xml name="stampede_tool" tokens="id">
            <tool id="@ID@" destination="dynamic_stampede_select" handler="multi_handlers" resources="stampede"/>
        </xml>
        <xml name="stampede_resubmit_tool" tokens="id">
            <tool id="@ID@" destination="dynamic_local_stampede_select_dynamic_walltime" handler="multi_handlers" resources="local_or_stampede" />
        </xml>
        <xml name="bridges_tool" tokens="id">
            <tool id="@ID@" destination="dynamic_bridges_select" handler="multi_handlers" resources="bridges"/>
        </xml>
    </macros>
</job_conf>
