---
#
# This file is maintained by Ansible - CHANGES WILL BE OVERWRITTEN
#

# WARNING: this file is shared between Test and Main!

# by default, tools are assigned 1 core, 8 GB of memory, and a 36 hour walltime

# tools dict:
#   keys are long or short tool IDs
#   values are either:
#     - a string: alias to another key in the dictionary
#     - a dict: specifying params to check (for match), destination, and native spec param overrides
#     - a list of dicts: for multiple possibilities based on different param selection
#
#     keys (in the case of dict or list of dicts) are:
#
#       params (optional): a list of dicts of tool params that will be checked for a match:
#         name: tool param to check
#           - if the param value is a list, comparison will be against its first element
#           - if the param value refers to a dataset, comparison will be against the size
#           - if the param value refers to a dataset collection, comparison will be against the size of the first element
#         op (optional, default: '=='): comparison operation (python operator)
#         value: value against which to compare the tool param, using op
#           - value is the rhs of the operator: <param> <op> <value>
#           - if value is a list, comparisons are performed against all values and the param set is considered a match
#             if the comparison is true for any value in the list (i.e. a logical OR)
#           - if the comparison is against a size, the value will be converted from a size string  to bytes
#         type (optional, default: null): 'data_table_lookup' to perform a data table lookup using the tool param listed
#                                         in 'name' as the lookup key
#         if the type is 'data_table_lookup', additional params keys are:
#           table_name (required): data table name
#           lookup_column (optional, default: 'value'): data table column name to perform lookup on
#           value_column (optional, default: 'path'): data table column name providing the value to compare against
#           value_template (optional, default: '{value}'): str.format() string, allows manipulation of the lookup results.
#                                                          only 'value' (contents of value_column) is currently supported.
#
#       destination: a destination id in the Galaxy job conf or a destination grouping in the destinations: section
#
#       spec: dict of native spec params. keys/values not valid for whatever destination is ultimately chosen will be
#             ignored. if the key is already specified in the native spec for a dest, the value is overridden with the
#             one in spec. if not, the key/val are appended to the native spec. subject to authorization in the
#             'destinations' section below.
#
#   - the destination/spec for the first set of matching param(s) is used
#   - if no params match, a default (dict without a 'params' key is used)
#   - if no default is specified, a hardcoded default in job_router.py is used

tools:

  _default_: {destination: slurm_normal}
  #_galaxy_lib_: {destination: slurm_normal_galaxy_env}
  #_default_: {destination: slurm_normal_direct}
  _galaxy_lib_: {destination: slurm_normal_direct}

  # these are for once you flip the switch on the defaults above (but we should make these work in Singularity!)
  upload1: {destination: slurm_normal_direct}
  __DATA_FETCH__: {destination: slurm_normal_direct}

  # python 2 legacy tools
{% for tool_id in galaxy_python2_legacy_tools %}
{% set short_tool_id = tool_id.split('/')[-2] %}
  {{ tool_id }}: {destination: slurm_{{ (short_tool_id in galaxy_multicore_tools) | ternary('multi', 'normal') }}_py2_direct}
{% endfor %}

  # tools not yet tested in Singularity - normal w/ default memory and multicore
{% for tool_id in galaxy_conda_tools %}
{% if '/' in tool_id %}
{% set short_tool_id = tool_id.split('/')[-2] %}
{% else %}
{% set short_tool_id = tool_id %}
{% endif %}
{% if short_tool_id in galaxy_multicore_tools %}
{% if short_tool_id in galaxy_pulsar_incompatible_tools %}
  {{ tool_id }}: {destination: slurm_multi_direct, login_required: true}
{% else %}
  {{ tool_id }}: {destination: multi_direct, login_required: true}
{% endif %}
{% else %}
  {{ tool_id }}: {destination: slurm_normal_direct}
{% endif %}
{% endfor %}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: antigenic1/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: antigenic1/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: backtranseq2/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: backtranseq2/6.6.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: banana3/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: biosed4/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: btwisted5/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cai6/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cai_custom6/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: chaos7/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: charge8/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: charge8/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: checktrans9/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: checktrans9/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: chips10/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cirdna11/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: codcmp12/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: coderet13/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: compseq14/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: compseq14/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cpgplot15/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cpgreport16/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cpgreport16/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cusp17/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cutseq18/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: cutseq18/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dan19/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dan19/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: degapseq20/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: descseq21/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: diffseq22/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: diffseq22/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: digest23/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dotmatcher24/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dotmatcher24/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dotpath25/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dotpath25/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dottup26/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dottup26/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dreg27/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: dreg27/5.0.0+galaxy1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: einverted28/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: einverted28/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: epestfind29/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: epestfind29/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: equicktandem31/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: equicktandem31/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: est2genome32/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: est2genome32/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: etandem33/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: etandem33/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: extractfeat34/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: extractfeat34/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: extractseq35/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: freak36/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: freak36/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: fuzznuc37/5.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: fuzznuc37/5.0.2': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: fuzzpro38/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: fuzzpro38/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: fuzztran39/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: fuzztran39/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: garnier40/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: geecee41/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: getorf42/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: getorf42/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: helixturnhelix43/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: helixturnhelix43/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: hmoment44/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: hmoment44/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: iep45/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: iep45/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: infoseq46/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: isochore47/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: isochore47/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: lindna48/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: lindna48/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: marscan49/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: maskfeat50/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: maskseq51/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: matcher52/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: matcher52/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: megamerger53/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: megamerger53/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: merger54/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: merger54/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: msbar55/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: msbar55/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: needle56/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: needle56/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: newcpgreport57/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: newcpgreport57/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: newcpgseek58/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: newcpgseek58/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: newseq59/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: noreturn60/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: notseq61/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: nthseq62/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: nthseq62/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: octanol63/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: octanol63/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: oddcomp64/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: oddcomp64/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: palindrome65/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: palindrome65/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pasteseq66/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pasteseq66/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: patmatdb67/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepcoil68/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepcoil68/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepinfo69/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepinfo69/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepnet70/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepstats71/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepwheel72/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepwheel72/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepwindow73/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepwindow73/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepwindowall74/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: pepwindowall74/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: plotcon75/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: plotcon75/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: plotorf76/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: polydot77/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: polydot77/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: preg78/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: preg78/5.0.0+galaxy1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: prettyplot79/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: prettyplot79/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: prettyseq80/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: prettyseq80/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: primersearch81/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: primersearch81/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: revseq82/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: seqmatchall83/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: seqmatchall83/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: seqret84/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: showfeat85/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: showfeat85/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: shuffleseq87/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: shuffleseq87/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: sigcleave88/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: sigcleave88/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: sirna89/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: sixpack90/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: sixpack90/5.0.0+galaxy2': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: skipseq91/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: skipseq91/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: splitter92/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: splitter92/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: supermatcher95/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: supermatcher95/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: syco96/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: syco96/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: tcode97/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: tcode97/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: textsearch98/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: tmap99/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: tranalign100/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: transeq101/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: trimest102/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: trimest102/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: trimseq103/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: trimseq103/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: twofeat104/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: twofeat104/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: union105/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: vectorstrip106/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: vectorstrip106/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: water107/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: water107/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: wobble108/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: wobble108/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: wordcount109/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: wordcount109/5.0.0.1': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: wordmatch110/5.0.0': {destination: slurm_normal_direct}
  'toolshed.g2.bx.psu.edu/repos/devteam/emboss_5/EMBOSS: wordmatch110/5.0.0.1': {destination: slurm_normal_direct}

  # 6 cores (roundup) or 10 cores (jetstream), 30 GB of memory, and a 36 hour walltime
{# this is a large automatically generated list maintained in env/<env>/group_vars/galaxyservers/tools_conf.yml #}
{% for tool_id in galaxy_multicore_tools %}
{% if tool_id in galaxy_pulsar_incompatible_tools %}
  {{ tool_id }}: {destination: slurm_multi, login_required: true}
{% else %}
  {{ tool_id }}: {destination: multi, login_required: true}
{% endif %}
{% endfor %}

  # Old versions not yet tested in Singularity
  toolshed.g2.bx.psu.edu/repos/devteam/join/gops_join_1/1.0.0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/devteam/varscan_version_2/varscan/0.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/devteam/varscan_version_2/varscan/2.4.2: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/devteam/scatterplot/scatterplot_rpy/1.0.0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/devteam/scatterplot/scatterplot_rpy/1.0.3: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/lparsons/htseq_count/htseq_count/0.6.1galaxy1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/lparsons/htseq_count/htseq_count/0.6.1galaxy3: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/lparsons/htseq_count/htseq_count/0.9.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/devteam/flanking_features/flanking_features_1/4.0.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/collection_column_join/collection_column_join/0.0.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/collection_column_join/collection_column_join/0.0.3: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/nilesh/rseqc/rseqc_read_duplication/2.6.4: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/nilesh/rseqc/rseqc_RPKM_saturation/2.6.4: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/nilesh/rseqc/rseqc_RPKM_saturation/2.6.4.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/nilesh/rseqc/rseqc_bam2wig/2.6.4: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/seqtk/seqtk_sample/1.2.0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/seqtk/seqtk_sample/1.3.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/seqtk/seqtk_sample/1.3.2: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/ggplot2_heatmap2/ggplot2_heatmap2/2.2.1+galaxy0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/ggplot2_heatmap2/ggplot2_heatmap2/2.2.1+galaxy1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/ggplot2_heatmap2/ggplot2_heatmap2/3.0.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.2: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.3: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.4: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.5: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.6: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.1.7: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/0.2: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/1.0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/kc_align/kc-align/1.0.2: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/variant_analyzer/read2mut/1.0.0: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/variant_analyzer/read2mut/1.0.1: {destination: slurm_normal_16gb_direct}
  toolshed.g2.bx.psu.edu/repos/iuc/variant_analyzer/read2mut/2.0.0: {destination: slurm_normal_16gb_direct}
  Interval2Maf1: {destination: slurm_normal_32gb_direct}
  wig_to_bigWig: {destination: slurm_normal_64gb_direct}
  CONVERTER_bedgraph_to_bigwig: {destination: slurm_normal_64gb_direct}

  # TODO: removing outliers > 100GB that were probably due to runaway memory in a job where limits weren't working, many
  # tools in the following sections probably don't need this much memory

  # 1 core, 16 GB of memory, and a 36 hour walltime
  # tool uses < 6.5 GB 89.2% of the time
  join1: {destination: slurm_normal_16gb}
  gops_join_1: {destination: slurm_normal_16gb}
  varscan: {destination: slurm_normal_16gb}
  fastq_paired_end_joiner: {destination: slurm_normal_16gb}
  scatterplot_rpy: {destination: slurm_normal_16gb}
  htseq_count: {destination: slurm_normal_16gb}
  flanking_features_1: {destination: slurm_normal_16gb}
  cummeRbund: {destination: slurm_normal_16gb}
  collection_column_join: {destination: slurm_normal_16gb}
  rseqc_read_duplication: {destination: slurm_normal_16gb}
  rseqc_RPKM_saturation: {destination: slurm_normal_16gb}
  rseqc_bam2wig: {destination: slurm_normal_16gb}
  seqtk_sample: {destination: slurm_normal_16gb}
  ggplot2_heatmap2: {destination: slurm_normal_16gb}
  kc-align: {destination: slurm_normal_16gb}
  porechop: {destination: slurm_normal_16gb}
  read2mut: {destination: slurm_normal_16gb}
  # tool uses < 6.5 GB 90.8% of the time and is a good candidate for running w/ 8 GB and resubmitting on failure.
  annotatemyids: {destination: slurm_normal_16gb}
  # TODO: this can be a function of base pairs in the reference
  genrich: {destination: slurm_normal_16gb}
  cummeRbund: {destination: slurm_normal_16gb}

  # 1 core, 32 GB of memory, and a 36 hour walltime
  #Interval2Maf1: {destination: slurm_normal_32gb}

  # TODO: maybe just send these to stampede?
  # 1 core, 64 GB of memory, and a 36 hour walltime
  #wig_to_bigWig: {destination: slurm_normal_64gb}
  #CONVERTER_bedgraph_to_bigwig: {destination: slurm_normal_64gb}

  #
  # Tools with special mappings
  #

  # Singularity normal + py2
  gff_filter_by_attribute: {destination: slurm_normal_py2}
  toolshed.g2.bx.psu.edu/repos/devteam/fasta_filter_by_length/fasta_filter_by_length/1.1: {destination: slurm_normal_py2}
  toolshed.g2.bx.psu.edu/repos/devteam/short_reads_trim_seq/trim_reads/1.0.0: {destination: slurm_normal_py2}
  toolshed.g2.bx.psu.edu/repos/galaxyp/gffcompare_to_bed/gffcompare_to_bed/0.1.0: {destination: slurm_normal_py2}
  toolshed.g2.bx.psu.edu/repos/galaxyp/bed_to_protein_map/bed_to_protein_map/0.1.0: {destination: slurm_normal_py2}

  # Singularity normal + galaxy env (note: these should be handled by the job router if listed in galaxy-lib tools)
  gff_filter_by_feature_count: {destination: slurm_normal_galaxy_env}

  # Singularity normal + resolv.conf fix
  toolshed.g2.bx.psu.edu/repos/bgruening/uniprot_rest_interface/uniprot/0.2: {destination: slurm_normal_resolv_fix}
  toolshed.g2.bx.psu.edu/repos/iuc/trinotate/trinotate/3.1.1: {destination: slurm_normal_resolv_fix}
  toolshed.g2.bx.psu.edu/repos/iuc/trinotate/trinotate/3.2.1: {destination: slurm_normal_resolv_fix}

  # Singularity normal + conda/TS/Galaxy deps; we should try to fix or remove these over time
  # No datamash=1.0.6 container
  toolshed.g2.bx.psu.edu/repos/iuc/datamash_reverse/datamash_reverse/1.0.6: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/datamash_transpose/datamash_transpose/1.0.6: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/datamash_ops/datamash_ops/1.0.6: {destination: slurm_normal_conda}
  # No fastx_toolkit=0.0.13 container
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_artifacts_filter/cshl_fastx_artifacts_filter/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_renamer/cshl_fastx_renamer/0.0.11: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_quality_filter/cshl_fastq_quality_filter/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_clipper/cshl_fastx_clipper/1.0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_reverse_complement/cshl_fastx_reverse_complement/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_trimmer/cshl_fastx_trimmer/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fasta_nucleotide_changer/cshl_fasta_nucleotides_changer/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_quality_converter/cshl_fastq_quality_converter/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_collapser/cshl_fastx_collapser/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fasta_formatter/cshl_fasta_formatter/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_quality_statistics/cshl_fastx_quality_statistics/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_nucleotides_distribution/cshl_fastx_nucleotides_distribution/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastx_barcode_splitter/cshl_fastx_barcode_splitter/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_quality_boxplot/cshl_fastq_quality_boxplot/1.0.0: {destination: slurm_normal_conda}
  # No ea-utils=1.1.2-806 container
  toolshed.g2.bx.psu.edu/repos/lparsons/fastq_join/fastq_join/1.1.2-806.1: {destination: slurm_normal_conda}
  # No gnu_coreutils container, but most of these could probably run in the legacy container without traditional deps
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_cat/0.1.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_cut_tool/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_easyjoin_tool/1.0.0: {destination: slurm_normal_conda}
  # In this case, the conda dep is actually broken since grep is compiled without PCRE support, so just use the
  # container grep
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/1.0.0:
    destination: slurm_normal_conda
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/corral4/main/singularity/usegalaxy.org-legacy-environment--0"}]
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_head_tool/1.0.0: {destination: slurm_normal_conda}
  # Can't find strict.pm?
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_multijoin_tool/1.0.0:
    destination: slurm_normal_conda
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/corral4/main/singularity/usegalaxy.org-legacy-environment--0"}]
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_sed_tool/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_sort_header_tool/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_sorted_uniq/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_tac/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_tail_tool/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_text_file_with_recurring_lines/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_unfold_column_tool/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_uniq_tool/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_sort_rows/1.0.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_sort_rows/1.1.0: {destination: slurm_normal_conda}
  # Has requirement for cutadapt but also needs /usr/bin/perl
  toolshed.g2.bx.psu.edu/repos/bgruening/trim_galore/trim_galore/0.4.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/trim_galore/trim_galore/0.4.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/bgruening/trim_galore/trim_galore/0.4.2: {destination: slurm_normal_conda}
  #
  toolshed.g2.bx.psu.edu/repos/devteam/tabular_to_fasta/tab2fasta/1.1.0: {destination: slurm_normal_conda}
  # samtools:0.1.16 image is broken and needs rebuild: /usr/local/bin/samtools: error while loading shared libraries: libncurses.so.5: cannot open shared object file: No such file or directory
  toolshed.g2.bx.psu.edu/repos/devteam/sam_pileup/sam_pileup/1.1.3: {destination: slurm_normal_conda}
  # no mulled container for requirements and it's too old to create one
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/0.0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/0.0.2: toolshed.g2.bx.psu.edu/repos/devteam/bamtools/bamtools/0.0.1
  # dunno, can't look these all up
  toolshed.g2.bx.psu.edu/repos/devteam/sam2interval/sam2interval/1.0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools_split/bamSplit/0.0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools_split/bamSplit/0.0.2: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/0.0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/0.0.2: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bamtools_filter/bamFilter/0.0.2: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/sam_to_bam/sam_to_bam/1.1.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/samtools_slice_bam/samtools_slice_bam/0.0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/sam_bitwise_flag_filter/sam_bw_filter/1.0.0: {destination: slurm_normal_conda}
  # no bedtools:2.24.* biocontainer for whatever reason
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_makewindowsbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_maskfastabed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_overlapbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_genomecoveragebed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_flankbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_expandbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_randombed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_slopbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedtobam/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bedpetobam/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_nucbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_multicovtbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_fisher/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_tagbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_map/2.24.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bed12tobed6/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_clusterbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_multiintersectbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_reldistbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_windowbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_links/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_mergebed/2.24.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_intersectbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_complementbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_shufflebed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_getfastabed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bamtobed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_jaccard/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_groupbybed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_closestbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_spacingbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_subtractbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_sortbed/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_coveragebed/2.24.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_annotatebed/2.24.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_unionbedgraph/2.24.0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_bamtofastq/2.24.0: {destination: slurm_normal_conda}
  # bedtools=2.27.0 samtools=1.2 mulled container
  # mulled-v2-8186960447c5cb2faa697666dc1e6d919ad23f3e:a3d46a26ecaad496382e8fcc83f7febe12e6c81f-0 has broken samtools
  # also this tool uses bash syntax so we have to override /bin/sh
  toolshed.g2.bx.psu.edu/repos/iuc/bedtools/bedtools_coveragebed/2.27.0.3:
    destination: slurm_normal_conda
    container_override: [{type: singularity, shell: '/bin/bash', resolve_dependencies: true, identifier: "/corral4/main/singularity/usegalaxy.org-legacy-environment--0"}]
  # missing python dep, this runs in the biocontainer but prepends Galaxy's venv to $PATH, probably should rename this
  # dest to be more apparent what it is
  toolshed.g2.bx.psu.edu/repos/iuc/bcftools_plugin_counts/bcftools_plugin_counts/1.9+galaxy1: {destination: slurm_normal_galaxy_env}
  toolshed.g2.bx.psu.edu/repos/iuc/bcftools_stats/bcftools_stats/1.9+galaxy1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcf2tsv/vcf2tsv/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfaddinfo/vcfaddinfo/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfallelicprimitives/vcfallelicprimitives/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfannotate/vcfannotate/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfannotategenotypes/vcfannotategenotypes/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfbedintersect/vcfbedintersect/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfbreakcreatemulti/vcfbreakcreatemulti/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfcheck/vcfcheck/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfcombine/vcfcombine/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfcombine/vcfcombine/0.0.4: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfcommonsamples/vcfcommonsamples/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcffixup/vcffixup/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfflatten/vcfflatten2/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfgeno2haplo/vcfgeno2haplo/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfgenotypes/vcfgenotypes/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfhethom/vcfhethom/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfleftalign/vcfleftalign/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfprimers/vcfprimers/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfrandomsample/vcfrandomsample/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfsort/vcfsort/1.0.0_rc3+galaxy0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfsort/vcfsort/0.0.2: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfsort/vcfsort/1.0.0_rc1+galaxy0: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfvcfintersect/vcfvcfintersect/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfselectsamples/vcfselectsamples/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcfdistance/vcfdistance/0.0.3: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcftools_annotate/vcftools_annotate/0.1: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/vcftools_slice/vcftools_slice/0.1: {destination: slurm_normal_conda}

  # Singularity multi + conda/TS/Galaxy deps;
  toolshed.g2.bx.psu.edu/repos/pjbriggs/trimmomatic/trimmomatic/0.32.3: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/pjbriggs/trimmomatic/trimmomatic/0.36.2: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/pjbriggs/trimmomatic/trimmomatic/0.36.3: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/pjbriggs/trimmomatic/trimmomatic/0.36.5: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/crs4/prokka/prokka/1.12.0: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/crs4/prokka/prokka/1.13: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bowtie2/bowtie2/0.2: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bowtie2/bowtie2/0.3: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bowtie2/bowtie2/0.4: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bowtie2/bowtie2/2.2.6: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/bowtie2/bowtie2/2.2.6.2: {destination: slurm_multi_conda}
  toolshed.g2.bx.psu.edu/repos/iuc/quast/quast/4.6.3: {destination: slurm_multi_conda}

  # There is a fastqc=0.10.1 container but the tool is missing a dep on python=2.7
  # TODO: this should become a standard environment, possibly just the regular image for slurm_normal_conda
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.52: {destination: slurm_normal_conda}
  #  destination: slurm_normal_conda
  #  # this doesn't work because these early versions are python wrappers around perl scripts around a java application
  #  container_override: [{type: singularity, shell: '/bin/sh', resolve_dependencies: true, identifier: "/corral4/main/singularity/usegalaxy.org-legacy-environment--0"}]
  #  # nope, no perl...
  #  container_override: [{type: singularity, shell: '/bin/sh', resolve_dependencies: true, identifier: "/cvmfs/singularity.galaxyproject.org/all/centos:7.9.2009"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.63: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.64: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.65: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.67: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.68: {destination: slurm_normal_conda}
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.69: {destination: slurm_normal_conda}
  # FIXME: something seems wrong here, container should be good but singularity seems to die and java continues to run
  # outside container?
  toolshed.g2.bx.psu.edu/repos/devteam/fastqc/fastqc/0.71: {destination: slurm_normal_conda}

  # Singularity w/ forced container and other special cases

  # as of 21.09, has no requirement tags
  addValue:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]
  Paste1:
    destination: slurm_normal
    # coreutils=8.25,perl=5.22.0.1
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/mulled-v2-c5660771860859a51697ce13d5d74251dc4c8eb6:254c9751502b0d56aa64890243ee9ebd88e94048-0"}]
  Remove beginning1:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]
  Condense characters1:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]
  createInterval:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]
  Cut1:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]
  ChangeCase:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]
  Extract_features1:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/bx-python:0.8.9--py38hb90e610_2"}]
  comp1:
    destination: slurm_normal
    # python=3.7,coreutils=8.30
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/mulled-v2-879928bcdd8adc5b4660a3f6de3703d7c7861de4:6ce96688844d469d84f94fabb34055d8dfa283c7-0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_trimmer/fastq_trimmer/1.0.0:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_trimmer_by_quality/fastq_quality_trimmer/1.0.0:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_combiner/fastq_combiner/1.0.1:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_filter/fastq_filter/1.0.0:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_groomer/fastq_groomer/1.0.4:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_manipulation/fastq_manipulation/1.0.1:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_masker_by_quality/fastq_masker_by_quality/1.0.0:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_paired_end_splitter/fastq_paired_end_splitter/1.0.0:
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_paired_end_joiner/fastq_paired_end_joiner/1.0.0:
    destination: slurm_normal_16gb
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/devteam/fastq_stats/fastq_stats/1.0.0:
    destination: slurm_normal_16gb
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/galaxy_sequence_utils:1.0.0--py27_0"}]
  toolshed.g2.bx.psu.edu/repos/bgruening/find_subsequences/bg_find_subsequences/0.2:
    # depends: biopython 1.65, but no container exists
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/biopython:1.66--np110py36_0"}]

  toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.3.1:
    # container exists but Galaxy picks the python 3 version, which needs this due to
    # https://click.palletsprojects.com/en/7.x/python3/#python-3-surrogate-handling
    destination: slurm_normal
    env: [{name: LC_ALL, value: C.UTF-8}, {name: SINGULARITYENV_LC_ALL, value: $LC_ALL}]
  toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.5.0: toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.3.1
  toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.6: toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.3.1
  toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.7: toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.3.1
  toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.7.1: toolshed.g2.bx.psu.edu/repos/iuc/multiqc/multiqc/1.3.1
  toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/pileup_interval/1.0.3:
    # no idea why this does not work automatically as the tool has a defined requirement on bx-python 0.7.1
    destination: slurm_normal
    container_override: [{type: singularity, shell: '/bin/sh', identifier: "/cvmfs/singularity.galaxyproject.org/all/bx-python:0.7.1"}]
  toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/pileup_interval/1.0.0: toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/pileup_interval/1.0.3
  toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/pileup_interval/1.0.2: toolshed.g2.bx.psu.edu/repos/devteam/pileup_interval/pileup_interval/1.0.3

  # FIXME: disabled while we try to figure out locking issues
  #toolshed.g2.bx.psu.edu/repos/iuc/medaka_consensus/medaka_consensus/1.0.3+galaxy2: {destination: slurm_multi_resolv_fix, login_required: true}

  # Valiant efforts but no luck
  # No fontconfig=2.11.1,rpy=1.0.3,R=2.11.0 container
  #toolshed.g2.bx.psu.edu/repos/devteam/short_reads_figure_score/quality_score_distribution/1.0.2:
  #  destination: slurm_normal_conda
  #  container_override: [{type: singularity, shell: '/bin/sh', resolve_dependencies: true, identifier: "/cvmfs/singularity.galaxyproject.org/all/python:2.7.16"}]
  # No perl dependency, seems not work with 5.22 (EL7 has 5.16)
  #toolshed.g2.bx.psu.edu/repos/devteam/fastx_barcode_splitter/cshl_fastx_barcode_splitter/1.0.0:
  #  destination: slurm_normal_conda
  #  container_override: [{type: singularity, shell: '/bin/sh', resolve_dependencies: true, identifier: "/cvmfs/singularity.galaxyproject.org/all/perl:5.22.0--9"}]

  # Multicore tools that are not Pulsar/Jetstream friendly

  # https://github.com/galaxyproject/tools-iuc/pull/3420
  # add version comparison to job_router and you can undo this for newer versions
  #deseq2: {destination: slurm_multi_direct, login_required: true}
  # still investigating
  #stringtie: {destination: slurm_multi_direct, login_required: true}

  # STAR=fusion uses all_fasta, not rnastar_index2, and more details about the memory usage is needed
  star_fusion:
    destination: jetstream_tacc_xlarge_direct
    login_required: true

  # STARSolo uses the same params and has the same requirements as STAR
  rna_starsolo: rna_star

  # STAR goes to either standard multi partitions (roundup/jetstream) or a special Jetstream m1.xlarge partition
  rna_star:
    # small input test
    #   nope - STAR memory requirements are based on the size of the reference
    #- params:
    #  - name: sc.input_types.input1
    #    op: '<'
    #    value: 100M
    #  destination: multi
    # for built-in refs we need (refsize * 1.5) + 2GB
    - params:
      - name: refGenomeSource.geneSource
        value: indexed
      - name: refGenomeSource.GTFconditional.genomeDir
        type: data_table_lookup
        table_name: rnastar_index2x_versioned
        value_template: '{value}/SA'
        op: '<'
        value: 18G
      destination: multi_direct
      login_required: true
    # same as above but for older versions of the tool
    - params:
      - name: refGenomeSource.geneSource
        value: indexed
      - name: refGenomeSource.GTFconditional.genomeDir
        type: data_table_lookup
        table_name: rnastar_index2
        value_template: '{value}/SA'
        op: '<'
        value: 18G
      destination: multi_direct
      login_required: true
    - params:
      - name: refGenomeSource.geneSource
        value: indexed
      destination: jetstream_tacc_xlarge_direct
      login_required: true

    # for history refs we need (refsize * 11.0) + 2GB
    - params:
      - name: refGenomeSource.geneSource
        value: history
      - name: refGenomeSource.genomeFastaFiles
        op: '<'
        value: 2.5G
      destination: multi
      login_required: true
    - params:
      - name: refGenomeSource.geneSource
        value: history
      destination: jetstream_tacc_xlarge_direct
      login_required: true

    # this should cover all cases, otherwise go to normal where it will probably fail and we can investigate
    #- destination: slurm_normal

  # TODO: refine, but per Bjrn "start with 52"
  #hifiasm:
  #  destination: jetstream_tacc_xlarge
  #  login_required: true

  # Kraken goes to Stampede 2 SKX if the bacteria database is selected, otherwise it goes to standard multi
  kraken:
    # can be a list if you want to do different things with different params (or one thing with no checked params)
    - params:
        - name: kraken_database
          value: bacteria
      # can be a real id or key in 'destinations' dict below
      destination: stampede_skx_normal
      login_required: true
    - destination: multi_direct
      login_required: true

  kraken2:
    - params:
      - name: kraken2_database
        type: data_table_lookup
        table_name: kraken2_databases
        value_template: '{value}/hash.k2d'
        op: '>'
        value: 84G
      destination: stampede_skx_normal
      login_required: true
    - params:
      - name: kraken2_database
        type: data_table_lookup
        table_name: kraken2_databases
        value_template: '{value}/hash.k2d'
        op: '>'
        value: 24G
      destination: jetstream_tacc_xlarge_direct
      #destination: stampede_normal
      login_required: true
    - destination: multi_direct
      login_required: true

  # align_families gets 192 hours of walltime
  align_families:
    destination: slurm_multi_long
    login_required: true
    spec:
     time: 192

  #fasterq_dump:
  #  destination: multi_long
  #  login_required: true

  #
  # Bridges Tools
  #

  abyss-pe:
    destination: frontera_small
    login_required: true

  # SPAdes (and thus Unicycler) uses at most 250GB
  spades:
    - params:
        - {name: libraries.files.file_type.type, value: separate}
        - {name: libraries.files.file_type.fwd_reads, op: '<', value: 100M}
      destination: multi_direct
      login_required: true
    - params:
        - {name: libraries.files.file_type.type, value: interleaved}
        - {name: libraries.files.file_type.interleaved_reads, op: '<', value: 200M}
      destination: multi_direct
      login_required: true
    - params:
        - {name: libraries.files.file_type.type, value: merged}
        - {name: libraries.files.file_type.merged_reads, op: '<', value: 100M}
      destination: multi
      login_required: true
    - params:
        - {name: libraries.files.file_type.type, value: unpaired}
        - {name: libraries.files.file_type.unpaired_reads, op: '<', value: 100M}
      destination: multi_direct
      login_required: true
    - params:
        - {name: libraries.files.file_type.type, value: paired-collection}
        - {name: libraries.files.file_type.fastq_collection, op: '<', value: 100M}
      destination: multi_direct
      login_required: true
    - destination: frontera_small
      login_required: true
      env:
        # SPAdes uses 2GB+ per thread regardless of what you set the memory limit to, so we have to decrease the threads
        # to avoid using too much memory
        - name: GALAXY_SLOTS
          value: "24"
    #destination: bridges_normal
    #login_required: true
    #spec:
    #  mem: 288G
    #env:
    #  #- name: GALAXY_MEMORY_MB
    #  #  value: "245760"
    #  - name: GALAXY_SLOTS
    #    value: "64"
    #  # TODO: appropriate value for Bridges-2?
    #  - execute: ulimit -s 24576

  unicycler:
    - params:
        #- {name: paired_unpaired.fastq_input_selector, value: [paired, paired_collection, single]}
        - {name: paired_unpaired.fastq_input1, op: '>', value: 800M}
      destination: frontera_small
      login_required: true
      env:
        - name: GALAXY_SLOTS
          value: "24"
    # Use multi for all (but Bridges can be selected from the resource selector)
    - destination: multi_direct
      login_required: true
  #  # Use multi for very small (e.g. training) datasets
  #  - params:
  #      - {name: paired_unpaired.fastq_input1, op: '<', value: 100M}
  #    destination: multi
  #  # Otherwise standard Bridges
  #  - destination: bridges_normal
  #    #spec:
  #    #  mem: 288G
  #    env:
  #      - execute: ulimit -s 24576

  # Users should use the new version of Trinity
  trinity_psc:
    destination: bridges_normal
    login_required: true

  trinity:
    # first matching param set is used
    # for collection params, comparison is implicitly on size of pair member 0

    # normalizing inputs < 10GB get 5 * 48GB = 240GB
    - params:
        - {name: pool.inputs.paired_or_single,  value: [single, unmerged_single_collection]}
        - {name: pool.inputs.input, op: '<', value: 10G}
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 240G, time: 72}
    - params:
        - {name: pool.inputs.paired_or_single,  value: paired}
        - {name: pool.inputs.left_input, op: '<', value: 10G}
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 240G, time: 72}
    - params:
        - {name: pool.inputs.paired_or_single, value: [paired_collection, unmerged_paired_collection]}
        - {name: pool.inputs.pair_input, op: '<', value: 10G}
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 240G, time: 72}

    # normalizing 10G <= inputs < 100G get 10 * 48GB = 480GB
    - params:
        - {name: pool.inputs.paired_or_single,  value: [single, unmerged_single_collection]}
        - {name: pool.inputs.input, op: '<', value: 100G}
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 480G, time: 96}
    - params:
        - {name: pool.inputs.paired_or_single,  value: paired}
        - {name: pool.inputs.left_input, op: '<', value: 100G}
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 480G, time: 96}
    - params:
        - {name: pool.inputs.paired_or_single, value: [paired_collection, unmerged_paired_collection]}
        - {name: pool.inputs.pair_input, op: '<', value: 100G}
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 480G, time: 96}

    # normalizing inputs >= 100G get 15 * 48GB = 720GB
    - params:
        - {name: norm, value: true}
      destination: frontera_small
      login_required: true
      #spec: {mem: 720G, time: 96}

    # not normalizing inputs < 10GB get 10 * 48GB = 480GB
    - params:
        - {name: pool.inputs.paired_or_single,  value: [single, unmerged_single_collection]}
        - {name: pool.inputs.input, op: '<', value: 10G}
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 480G, time: 96}
    - params:
        - {name: pool.inputs.paired_or_single,  value: paired}
        - {name: pool.inputs.left_input, op: '<', value: 10G}
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 480G, time: 96}
    - params:
        - {name: pool.inputs.paired_or_single, value: [paired_collection, unmerged_paired_collection]}
        - {name: pool.inputs.pair_input, op: '<', value: 10G}
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 480G, time: 96}

    # not normalizing 10G <= inputs < 100G get 15 * 48GB = 720GB
    - params:
        - {name: pool.inputs.paired_or_single,  value: [single, unmerged_single_collection]}
        - {name: pool.inputs.input, op: '<', value: 100G}
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 720G, time: 96}
    - params:
        - {name: pool.inputs.paired_or_single,  value: paired}
        - {name: pool.inputs.left_input, op: '<', value: 100G}
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 720G, time: 96}
    - params:
        - {name: pool.inputs.paired_or_single, value: [paired_collection, unmerged_paired_collection]}
        - {name: pool.inputs.pair_input, op: '<', value: 100G}
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 720G, time: 96}

    # not normalizing inputs >= 100G get 20 * 48GB = 960GB
    - params:
        - {name: norm, value: false}
      destination: frontera_small
      login_required: true
      #spec: {mem: 960G, time: 96}

    # default if no matching params (shouldn't happen)
    - destination: frontera_small
      login_required: true
      spec: {time: 24}

  #
  # Stampede tools
  #
  bwa_color_wrapper: {destination: stampede_normal, login_required: true}
  bowtie_color_wrapper: {destination: stampede_normal, login_required: true}
  megablast_wrapper: {destination: stampede_normal, login_required: true}
  ncbi_blastn_wrapper: {destination: stampede_normal, login_required: true}
  ncbi_blastp_wrapper: {destination: stampede_normal, login_required: true}
  ncbi_blastx_wrapper: {destination: stampede_normal, login_required: true}
  ncbi_rpsblast_wrapper: {destination: stampede_normal, login_required: true}
  ncbi_tblastn_wrapper: {destination: stampede_normal, login_required: true}
  ncbi_tblastx_wrapper: {destination: stampede_normal, login_required: true}

  #
  # Frontera tools
  #
{% for tool_id in galaxy_frontera_tools %}
  {{ tool_id }}: {destination: frontera_small, login_required: true}
{% endfor %}
  busco:
    destination: frontera_small
    login_required: true
    spec:
      # busco crashes with the full thread count because it uses too much memory (even 12 was too many)
      ntasks: 10

# count of queued jobs in these destinations count against the other destinations (i.e. they're probably just slightly
# different params on the same queue)
share_job_counts:
  -
    - slurm_multi
    - slurm_multi_py2
    - slurm_multi_memory_resubmit
    - slurm_multi_long
    - slurm_reserved_multi
    - slurm_multi_direct
    - slurm_multi_py2_direct
    - slurm_multi_long_direct
  -
    - jetstream_iu_multi
    - jetstream_iu_multi_py2
    - jetstream_iu_multi_long
    #- reserved_jetstream_iu_multi
    - jetstream_iu_multi_direct
    - jetstream_iu_multi_py2_direct
    - jetstream_iu_multi_long_direct
  -
    - jetstream_tacc_multi
    - jetstream_tacc_multi_py2
    - jetstream_tacc_multi_long
    #- reserved_jetstream_tacc_multi
    - jetstream_tacc_multi_direct
    - jetstream_tacc_multi_py2_direct
    - jetstream_tacc_multi_long_direct

# TODO: now that share_job_counts is implemented, drop dict in list dests?
destinations:
  #normal_py2:
  #  - id: slurm_py2
  #  - id: jetstream_iu_normal_py2
  multi_py2:
    - id: slurm_multi_py2
    - id: jetstream_iu_multi_py2
      queue_factor: 2
    - id: jetstream_tacc_multi_py2
      queue_factor: 4
  multi_py2_direct:
    - id: slurm_multi_py2_direct
    - id: jetstream_iu_multi_py2_direct
      queue_factor: 2
    - id: jetstream_tacc_multi_py2_direct
      queue_factor: 4
  multi:
    - id: slurm_multi
    - id: jetstream_iu_multi
      # jetstream can run far fewer jobs than roundup, so we weight its job count by a factor of 2 since its throughput
      # will be lower
      queue_factor: 2
      # could also set threshold: on each member, default is 4
    - id: jetstream_tacc_multi
      queue_factor: 4
    - id: jetstream2_multi
      # temp limit jobs to JS2
      queue_factor: 8
  multi_direct:
    - id: slurm_multi_direct
    - id: jetstream_iu_multi_direct
      queue_factor: 2
    - id: jetstream_tacc_multi_direct
      queue_factor: 4
  reserved_multi:
    - id: slurm_reserved_multi
    # FIXME: not configured right in slurm
    #- id: reserved_jetstream_iu_multi
    #- id: reserved_jetstream_tacc_multi
  multi_long:
    - id: slurm_multi_long
    - id: jetstream_iu_multi_long
    - id: jetstream_tacc_multi_long
    - id: stampede_long
  jetstream_multi:
    - id: jetstream_iu_multi
      queue_factor: 2
    - id: jetstream_tacc_multi
      queue_factor: 4
  slurm_multi:
    valid:
      - time
  slurm_multi_long:
    valid:
      - time
  slurm_multi_long_direct:
    valid:
      - time
  jetstream_iu_multi:
    valid:
      - time
  jetstream_tacc_multi:
    valid:
      - time
  jetstream_tacc_xlarge:
    valid:
      - time
  stampede_normal:
    valid:
      - ntasks
      - time
    max:
      ntasks: 272
      time: 48
  stampede_development:
    valid:
      - ntasks
      - time
    max:
      ntasks: 272
    override:
      time: 2
  stampede_skx_normal:
    valid:
      - ntasks
      - time
    max:
      ntasks: 96
      time: 48
  stampede_skx_development:
    valid:
      - ntasks
      - time
    max:
      ntasks: 96
    override:
      time: 2
  #multi_long:
  #  max:
  #    time: 72
  #jetstream_iu_multi_long:
  #  max:
  #    time: 72
  stampede_long:
    max:
      time: 120
  frontera_small:
    valid:
      - ntasks
      - time
    max:
      ntasks: 56
      time: 48
  frontera_development:
    valid:
      - ntasks
      - time
    max:
      ntasks: 56
    override:
      time: 2
  bridges_normal:
    valid:
      #- mem
      - ntasks
      - time
    max:
      ntasks: 128
      time: 36
    override:
      time: 48
      #mem: 720G
    #normalize:
    #  mem: 48G
  bridges_development:
    valid:
      #- mem
      - ntasks
      - time
    max:
      ntasks: 128
    override:
      time: 2
    #override:
    #  mem: 720G
    #normalize:
    #  mem: 48G

groups:
  Job Priority Users:
    destination_overrides:
      slurm_normal: slurm_reserved_normal
      slurm_normal_16gb: slurm_reserved_normal_16gb
      slurm_normal_32gb: slurm_reserved_normal_32gb
      multi: reserved_multi
      slurm_normal_direct: slurm_reserved_normal_direct
      slurm_normal_16gb_direct: slurm_reserved_normal_16gb
      slurm_normal_32gb_direct: slurm_reserved_normal_32gb
      multi_direct: reserved_multi
  Job Test Users:
    destination_overrides:
      #slurm_upload: slurm_test_upload
      slurm_normal: slurm_test_normal
      slurm_normal_16gb: slurm_test_normal
      slurm_normal_32gb: slurm_test_normal
      slurm_normal_64gb: slurm_test_normal
      multi: slurm_test_normal
      slurm_multi: slurm_test_normal
      slurm_normal_conda: slurm_test_normal_conda
      slurm_normal_py2: slurm_test_normal_py2
      slurm_normal_galaxy_env: slurm_test_normal_galaxy_env
      slurm_normal_resolv_fix: slurm_test_normal_resolv_fix
      slurm_multi_conda: slurm_test_normal_conda
      slurm_multi_resolv_fix: slurm_test_normal_resolv_fix
      frontera_small: frontera_development
      stampede_normal: stampede_development
      stampede_skx_normal: stampede_skx_development
      bridges_normal: bridges_development
      bridges_shared_128gb: bridges_development
      bridges_shared_64gb: bridges_development
      bridges_extreme_1tb: bridges_development
      expanse_normal: expanse_development
      expanse_shared_128gb: expanse_development
      expanse_shared_64gb: expanse_development
      slurm_normal_direct: slurm_test_normal_direct
      slurm_normal_16gb_direct: slurm_test_normal_direct
      slurm_normal_32gb_direct: slurm_test_normal_direct
      slurm_normal_64gb_direct: slurm_test_normal_direct
      multi_direct: slurm_test_normal_direct
      slurm_multi_direct: slurm_test_normal_direct
      slurm_normal_py2_direct: slurm_test_normal_py2_direct
  Job Resource Param Users:
    param_overrides: true

training_tools:
  incompatible:
    # kraken2 loads the entire selected reference into memory regardless of the input size
    - kraken2
    # TODO: document why these don't work
    - unicycler
    - rna_starsolo
    - rna_star
    - minimap2
    - ncbi_blastp_wrapper
  mapping:
    _default_: slurm_training
    bowtie2: slurm_training_multi_large
    rseqc_geneBody_coverage: slurm_training_long
    genrich: slurm_training_large
    wig_to_bigWig: slurm_training_xlarge
